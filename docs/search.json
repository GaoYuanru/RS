[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Remote Sensing Cities and Environments Book",
    "section": "",
    "text": "Introduction\nHI, EVERYONE! HOPE YOU ALL HAVE A WONDERFUL DAY!"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Ramsey, M., Flynn, I., 2020. The Spatial and Spectral Resolution of ASTER Infrared Image Data: A Paradigm Shift in Volcanological Remote Sensing. Remote Sens. 12, 738. https://doi.org/10.3390/rs12040738 Verde, N., Mallinis, G., Tsakiri-Strati, M., Georgiadis, C., Patias, P., 2018. Assessment of Radiometric Resolution Impact on Remote Sensing Data Classification Accuracy. Remote Sens. 10, 1267. https://doi.org/10.3390/rs10081267 Bergsma, E.W.J., Almar, R., 2020. Coastal coverage of ESA’ Sentinel 2 mission. Adv. Space Res. 65, 2636–2644. https://doi.org/10.1016/j.asr.2020.03.001 Mishra, M.K., Rathore, P.S., Misra, A., Kumar, R., 2020. Atmospheric Correction of Multispectral VNIR Remote Sensing Data: Algorithm and Inter‐sensor Comparison of Aerosol and Surface Reflectance Products. Earth Space Sci. 7. https://doi.org/10.1029/2019EA000710 Schott, J.R., Hook, S.J., Barsi, J.A., Markham, B.L., Miller, J., Padula, F.P., Raqueno, N.G., 2012. Thermal infrared radiometric calibration of the entire Landsat 4, 5, and 7 archive (1982–2010). Remote Sens. Environ. 122, 41–49. https://doi.org/10.1016/j.rse.2011.07.022 Li, H., Zhang, G., Zhong, Q., Xing, L., Du, H., 2023. Prediction of Urban Forest Aboveground Carbon Using Machine Learning Based on Landsat 8 and Sentinel-2: A Case Study of Shanghai, China. Remote Sens. 15, 284. https://doi.org/10.3390/rs15010284 Sekertekin, A., Bonafoni, S., 2020. Land Surface Temperature Retrieval from Landsat 5, 7, and 8 over Rural Areas: Assessment of Different Retrieval Algorithms and Emissivity Models and Toolbox Implementation. Remote Sens. 12, 294. https://doi.org/10.3390/rs12020294 Venkatappa, M., Sasaki, N., Han, P., Abe, I., 2021. Impacts of droughts and floods on croplands and crop production in Southeast Asia – An application of Google Earth Engine. Sci. Total Environ. 795, 148829. https://doi.org/10.1016/j.scitotenv.2021.148829 Dong, L., Du, H., Mao, F., Han, N., Li, X., Zhou, G., Zhu, D., Zheng, J., Zhang, M., Xing, L., Liu, T., 2020. Very High Resolution Remote Sensing Imagery Classification Using a Fusion of Random Forest and Deep Learning Technique—Subtropical Area for Example. IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens. 13, 113–128. https://doi.org/10.1109/JSTARS.2019.2953234  Pal, M., 2005. Random forest classifier for remote sensing classification. Int. J. Remote Sens. 26, 217–222. https://doi.org/10.1080/01431160412331269698 Stock, A., 2022. Spatiotemporal distribution of labeled data can bias the validation and selection of supervised learning algorithms: A marine remote sensing example. ISPRS J. Photogramm. Remote Sens. 187, 46–60. https://doi.org/10.1016/j.isprsjprs.2022.02.023 Oukawa, G.Y., Krecl, P., Targino, A.C., 2022. Fine-scale modeling of the urban heat island: A comparison of multiple linear regression and random forest approaches. Sci. Total Environ. 815, 152836. https://doi.org/10.1016/j.scitotenv.2021.152836 Senanayake, I.P., Welivitiya, W.D.D.P., Nadeeka, P.M., 2013. Remote sensing based analysis of urban heat islands with vegetation cover in Colombo city, Sri Lanka using Landsat-7 ETM+ data. Urban Clim. 5, 19–35. https://doi.org/10.1016/j.uclim.2013.07.004"
  },
  {
    "objectID": "Chapter1.html",
    "href": "Chapter1.html",
    "title": "1  GYR",
    "section": "",
    "text": "[Caption for the picture. ]{width=“3000”}(image/R.jpeg){width=“50%”}"
  },
  {
    "objectID": "Chapter1.html#summary",
    "href": "Chapter1.html#summary",
    "title": "1  Chapter 1 - Introduction to Remote Sensing",
    "section": "1.1 Summary",
    "text": "1.1 Summary\n\n1.1.1 The two types of sensor\n\n\n\n\n\n\nActive sensor\n\n\n\n\n\n\n\nPassive sensor\n\n\n\n\n\nData source:source:NASA Science\n\n1.1.1.1 Active remote sensing content and example\nActive sensors have their own source of light or illumination. In particular, it actively sends a pulse and measures the backscatter reflected to the sensor.Active remote sensing comes in many forms. For example, they can be satellites orbiting the Earth, helicopters in the air, or anything on the ground too. Just as long as it has an active sensor.For the untrained eye, it’s just a bunch of black and white pixels. But the reality is that there’s more than meets the eye. For example, the 3 main types of backscatter are:\n\n\n\n\n\n\n\n\nSpecular reflection:Specular reflection is where dark spots are in the image. In this case, it’s the smooth surfaces like the east-west flowing river and paved surfaces.\nDouble-bounce:Specular reflection is where dark spots are in the image. In this case, it’s the smooth surfaces like the east-west flowing river and paved surfaces.\nDiffuse scattering:Finally, the majority of the radar image is rough surface and diffuse scattering. This may be from the growing vegetation in the agricultural areas. Passive remote sensing example\n\n\n\n\n\n\n\n\n\nsynthetic aperture radar image\n\n\n\n\n\n1.1.1.2 Passive remote sensing content and example\nPassive sensors use naturally emitted light from the sun. Without the sun, there wouldn’t be passive remote sensing. Really, passive remote sensing can be very similar to how our eyes interpret the world. For example, here are the Rocky Mountains in true color.But the power of passive remote sensing is to see light in the whole electromagnetic spectrum. For example, this multispectral image can have different band combinations like color infrared.\n\n\n\n\nRocky Mountains in true color image\n\n\n\nSource:GISGeography\n\n\n\n1.1.2 Four Remotely Sensing Resolutions\n\n\n\n\nflowchart LR\n  A[Four Remotely Sensing Resolutions] --> B(Spectral)\n  A[Four Remotely Sensing Resolutions] --> C(Spatial)\n  A[Four Remotely Sensing Resolutions] --> D(Temporal)\n  A[Four Remotely Sensing Resolutions] --> E(Radiometric)\n  B --> F(Spectral resolution refers to the specific wavelength intervals in the Electromagnetic spectrum that a sensor can record.)\n  C --> G(Spatial resolution is a measure of the smallest object that can be resolved by the sensor, or the area on the ground represented by each pixel.)\n  D --> H(Temporal resolution refers to how often a sensor obtains imagery of a particular area.)\n  E --> I(Radiometric resolution refers to the dynamic range, or number of possible data file values in each band. )\n\n\n\n\n\n\n\n\n\n\n\n\n\nsource:NASA Science\n\n\n\n\n\n1.1.3 Landsat\nThe Landsat program is the longest-running enterprise for acquisition of satellite imagery of Earth. It is a joint NASA / USGS program. On 23 July 1972, the Earth Resources Technology Satellite was launched. This was eventually renamed to Landsat 1 in 1975. The most recent, Landsat 9, was launched on 27 September 2021.\nThe instruments on the Landsat satellites have acquired millions of images. The images, archived in the United States and at Landsat receiving stations around the world, are a unique resource for global change research and applications in agriculture, cartography, geology, forestry, regional planning, surveillance and education, and can be viewed through the U.S. Geological Survey (USGS) “EarthExplorer” website.\n\n\n\n\nComparison of Landsat-7, Landsat-8, and Landsat-9 bands with Sentinel-2, ASTER, and MODIS bands\n\n\n\nSource:researchgate"
  },
  {
    "objectID": "Chapter1.html#reflection",
    "href": "Chapter1.html#reflection",
    "title": "1  Chapter 1 - Introduction to Remote Sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nIn the first week I learned about some common remote sensing data and applications from the course, as well as gained an initial understanding of remote sensing. I also learnt about basic concepts related to remote sensing such as sensors and electric waves. One of the things I felt most strongly about was the process of how remote sensing works. I also learnt from the course that the reason the moon appears to have a black sky is because it does not have an atmosphere to scatter and disperse sunlight. On Earth, the sky appears blue because the atmosphere scatters the short wavelengths of light from the sun (blue and violet) more than the longer wavelengths (red, orange and yellow), which makes it easier to see blue light. But the moon has no atmosphere, so there is no scattering, and the sky looks black even during the day. The oceans appear blue due to the way the water absorbs and reflects sunlight. When the sun shines on the ocean, the water absorbs all colours of light except blue, and the blue is reflected back to our eyes.I also learned that active remote sensing is the process of using sensors that emit energy (e.g. radar or lidar) to gather information about a target or object, which can be applied, for example, to agriculture, weather forecasting, etc. Passive remote sensing, on the other hand, is the process of detecting and measuring electromagnetic radiation emitted or reflected from objects or surfaces on the Earth without any active source of radiation and can be used for disaster response as well as Earth observation."
  },
  {
    "objectID": "Chapter1.html#applications",
    "href": "Chapter1.html#applications",
    "title": "1  Chapter 1 - Introduction to Remote Sensing",
    "section": "1.2 Applications",
    "text": "1.2 Applications\n\nThe Spatial and Spectral Resolution of ASTER Infrared Image Data: A Paradigm Shift in Volcanological Remote Sensing(Ramsey and Flynn, 2020)\n\nThis article points out that the success of the ASTER instrument design and mission has made it possible to capture high spatial, hyperspectral TIR data with ever-increasing temporal resolution. Multispectral TIR data can now be acquired on a regular basis, allowing the tracking of subtle thermal anomalies, precursor activity, explosive events, plumes and percentages of obscuration clouds. However, the paper highlights the need for further improvements to the TIR sensor system to improve its temporal resolution and reduce the percentage of misses between MODIS-based triggers and the number of ASTER scenes acquired from these triggers. The importance of temporal resolution in remote sensing data can also be seen, affecting the time scale of the data.\n\nAssessment of Radiometric Resolution Impact on Remote Sensing Data Classification Accuracy(Verde et al., 2018)\n\nThe study evaluated the role of radiometric resolution on classification accuracy, image information content, and computational complexity. The findings suggest that the impact of radiometric resolution on classification accuracy is low, at least in the experiments conducted in the study. However, in texture classification experiments, the classification accuracies showed differences of up to 7% in some cases. Overall, the research suggests that lower radiometric resolution is not always at the expense of classification accuracy, and it provides some hints on selecting or modifying radiometric resolution for certain classification tasks. However, future research could explore the interrelations between radiometric and other types of remote sensing resolutions and the impact of the classification algorithm used in the classification accuracy of various radiometric resolution images."
  },
  {
    "objectID": "Chapter6.html#summary",
    "href": "Chapter6.html#summary",
    "title": "6  Chapter 6 - Classification I",
    "section": "6.1 Summary",
    "text": "6.1 Summary\n\n\n\n\nMindmap\n\n\n\n\n\n6.1.1 Machine Learning\n\nWhat is Machine Learning? Machine learning = science of computer modeling of learning process;Machine learning this is a search through all the data to explain the input data and can be used on new input data.\n\n\n6.1.1.1 Classification and regression trees (CART)\n1.Classification trees classify data into two or more discrete (can only have certain values) categories 2. Regression trees predict continuous dependent variable\n\n\n\n\nDecision Tree\n\n\n\n Data source:Digital Vidya\n\nUse Gini impurityto quantify an impure leaf. Gini impurity= 1-(probability of yes)^2-(the probability of no)^2\n\n\n\n6.1.1.2 Random Forests\n\nRF characteristic\n\n\nWe get many, many different trees = a forest Run the data we have down the trees Which option gets more votes based on all the trees: Make decision tree from random number of variables (never all of them)\nWe get many, many different trees = a forest\nRun the data we have down the trees\nWhich option gets more votes based on all the trees\nBootstrapping (re-sampling by replacement data to make a decision = bagging):For each tree about 70% of the training data is used in the bootstrap, 30% is left out of the bag (OOB)\nProportion of OOB incorrectly classified = OOB error\nOften the number of variables per tree is calculated from square root of variables in the original data.\nOften the number of variables per tree is calculated from square root of variables in the original data.\nOut of Bag Error:All trees that didn’t have the values;Average prediction error - number of correct predicted/total\nValidation data: never included within the decision tree\n\n\n\n\n6.1.2 Unsupervised\n\n6.1.2.1 Maximum Likelyhood\n\n\n\n\n\n\n\n\n\nBasics\nSpecifics\n\n\n\n\nDecision rule classifier\nFrom histogram to probability density function\n\n\nUses probability\nIn imagery this is n dimensional multivariate normal density function\n\n\nTakes the image and assigns pixel to the most probable land cover type.\nEach pixel from image data is passed to the maximum likelihood rule > assigns landover to the largest product.\n\n\nTakes the image and assigns pixel to the most probable land cover type.\nBased on probability, the data (landcover) most probably to have the values in our pixel\n\n\n\n\n\nContent source:Andrew Maclachlan\n\n\n\n6.1.3 Supervised\n\n6.1.3.1 Support Vector Machine (SVM)\nSupport Vector Machine (SVM) is a relatively simple Supervised Machine Learning Algorithm used for classification and/or regression. It is more preferred for classification but is sometimes very useful for regression as well. Basically, SVM finds a hyper-plane that creates a boundary between the types of data. In 2-dimensional space, this hyper-plane is nothing but a line. In SVM, we plot each data item in the dataset in an N-dimensional space, where N is the number of features/attributes in the data. Next, find the optimal hyperplane to separate the data. So by this, you must have understood that inherently, SVM can only perform binary classification (i.e., choose between two classes). However, there are various techniques to use for multi-class problems. Support Vector Machine for Multi-CLass Problems To perform SVM on multi-class problems, we can create a binary classifier for each class of the data. The two results of each classifier will be :\nThe data point belongs to that class OR The data point does not belong to that class. For example, in a class of fruits, to perform multi-class classification, we can create a binary classifier for each fruit. For say, the ‘mango’ class, there will be a binary classifier to predict if it IS a mango OR it is NOT a mango. The classifier with the highest score is chosen as the output of the SVM. SVM for complex (Non Linearly Separable) SVM works very well without any modifications for linearly separable data. Linearly Separable Data is any data that can be plotted in a graph and can be separated into classes using a straight line.   Data source:geeksforgeeks"
  },
  {
    "objectID": "Chapter6.html#applications",
    "href": "Chapter6.html#applications",
    "title": "6  Chapter 6 - Classification I",
    "section": "6.2 Applications",
    "text": "6.2 Applications\nVery High Resolution Remote Sensing Imagery Classification Using a Fusion of Random Forest and Deep Learning Technique—Subtropical Area for Example(Dong et al., 2020)\n\nThis paper attempts a method based on the neural fusion of Random Forest (RF) classifiers and Convolutional Neural Network (CNN) and uses this fusion for forest mapping in very high resolution remote sensing (VHRRS). In a traditional CNN, the FC layer is used as the final decision base to calculate the likelihood of a pixel belonging to each class. But there are some drawbacks, such as the tendency to over-fit, especially when the sample size is not large enough. So in this paper, a fusion of RF and CNN is proposed in order to optimise the classification. The detailed method is shown in the figure, where the research team first trains the CNN end-to-end using images and labels. In the process, the CNN is trained until a relatively low loss and high accuracy is achieved. The feature maps are then obtained by processing the images using the trained CNNs. This paper has two advantages over other research papers in the same field. Firstly a test was carried out to confirm whether the fusion of CNN and RF could improve VHRRS information extraction. The second is based on RF and the selection of variables with high importance. The test was then conducted again to confirm whether learning from the selected variables would further provide better results. The current shortcoming of this model is that the model is computationally intensive and therefore requires a high level of hardware equipment and cannot be adapted to most computer equipment.\n\n\n\n\n\nOverview of our approaches\n\n\n\n\nRandom forest classifier for remote sensing classification(Pal, 2005)\n\nThis article is an early comparison of SVM and random forest applications in remote sensing classification. Using Landsat Enhanced Thematic Mapper Plus (ETM+) data for a region of the UK with seven different land covers, the performance of a random forest classifier is compared with that of a support vector machine (SVM) in terms of classification accuracy, training time and user-defined parameters. It was concluded that the random forest classifier can achieve classification accuracies comparable to those achieved by support vector machines. Another advantage of the Random Forest classifier is that it only requires two parameters to be set, whereas the SVM requires many user-defined parameters. The random forest classifier can handle categorical data, unbalanced data and data with missing values, which is not easy for SVMs to do. The classifier also provides the relative importance of different features in the classification process, which is useful in feature selection. In addition, the random forest classifier provides a method for detecting outliers by using proximity analysis, which can be used for unsupervised learning."
  },
  {
    "objectID": "Chapter6.html#reflection",
    "href": "Chapter6.html#reflection",
    "title": "6  Chapter 6 - Classification I",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\nIt has been a very rewarding week of learning about remote sensing. I understood that the reason why images are classified is because of the need to estimate values of practical significance such as GCSE scores or pollution indices with the help of remote sensing images. Also learnt that the predecessor to machine learning was having a priori knowledge or experts developing rules and then importing the rules into a computer. The decision tree part was very interesting, using the Gini coefficient, always looking for the lowest point, finding it and then splitting it in two to build the tree and repeating this step. It is important to note that the left part of the data is used to build the tree, while the right is used to continue finding the lowest point for classification. The most challenging part is the SVM, which allows misclassification of data to occur, and I have to study this part in depth to get a more accurate and detailed understanding."
  },
  {
    "objectID": "Chapter7.html#summary",
    "href": "Chapter7.html#summary",
    "title": "7  Chapter 7 - Classification II",
    "section": "7.1 Summary",
    "text": "7.1 Summary\n\n7.1.1 Object based image analysis and sub pixel analysis\n\n7.1.1.1 Object based image analysis\n\nInstead of considering cells we consider shapes based on the similarity (homogeneity) or difference (heterogeneity) of the cells = superpixels SLIC (Simple Linear Iterative Clustering) Algorithm for Superpixel generation is the most common method\n\n\n\n7.1.1.2 Sub pixel analysis\n\nSMA determines the proportion or abundance of landcover per pixel\nthe assumption that reflectance measured at each pixel is represented by the linear sum of endmembers weighted by the associated endmember fraction\nTypically we have a few endmembers that are spectrally pure\nSum of end member reflectance * fraction contribution to best-fit mixed spectrum\n\n\n\n\n\nFormula\n\n\n\n\n\n\n7.1.2 Assess the accuracy\n\nConfusion Matrix: Date: February 17, 2019 Author: Rachel Draelos, MD, PhD Confusion matrices are calculated using the predictions of a model on a data set. By looking at a confusion matrix, you can gain a better understanding of the strengths and weaknesses of your model, and you can better compare two alternative models to understand which one is better for your application. Traditionally, a confusion matrix is calculated using a model’s predictions on a held-out test set.\n\n\n\n\nConfusion Matrix\n\n\n\nData source:glassboxmedicine\nproducer’s accuracy defined as the fraction of correctly classified pixels (TP) compared to ground truth data (TP+FN)*TP/(TP+FN)\nuser’s accuracy defined as the fraction of correctly classified pixels (TP) relative to all others classified as a particular land cover (TP+FP)*TP/(TP+FP)-FP is different\noverall accuracy represents the combined fraction of correctly classified pixels (TP +TN) across all land cover types (TP+FP+FN+TN)*(TP+TN)/(TP+FP+TN+FN) Source: Barsi et al. 2018 Accuracy Dimensions in Remote Sensing\nA good Kappa value\n\n\n\n\nKappa Value\n\n\n\n\nSource: Explaining the unsuitability of the kappa coefficient in the assessment and comparison of the accuracy of thematic maps obtained by image classification. Foody 2020\n\n\n7.1.3 Cross Validation\nWhen we do the steps of fixed partition, we should consider Spatial autocorrelation between training and test sets!\n\n\n7.1.4 Spatial Cross Validation\n\nspatially partition the folded data, folds are from cross validation \ndisjoint (no common boundary) using k -means clustering (number of points and a distance) \nsame as cross validation but with clustering to the folds…\nstops our training data and testing data being near each other…\n\n\nin other words this makes sure all the points (or pixels) we train the model with a far away from the points (or pixels) we test the model with.\n\n\n\n\nCross Validation vs. Spatial Cross Validation\n\n\n\n\nSource: Illustration of default cross-validation vs. spatial cross-validation. Image from Lovelace, et al."
  },
  {
    "objectID": "Chapter7.html#applications",
    "href": "Chapter7.html#applications",
    "title": "7  Chapter 7 - Classification II",
    "section": "7.2 Applications",
    "text": "7.2 Applications\n\nSpatiotemporal distribution of labeled data can bias the validation and selection of supervised learning algorithms: A marine remote sensing example(Stock, 2022)\n\nThis paper highlights the potential biases that can occur when using supervised learning algorithms for marine remote sensing applications. Specifically, it highlights the importance of careful statistical design when creating and validating tagged datasets for such applications. The paper also compares different validation statistical designs and shows that a combination of using multiple validation methods and critically discussing error estimates can help mitigate these biases. One of the more classic is the 10-fold cross-validation approach, where the data is divided into 10 random subsets of equal size, one after the other, with each fold kept only once, to validate the model trained on the remaining 9 folds. There is also spatial leave-one-out cross-validation, in which each observation is left out only once for validation, while all other observations are used for training. This approach has been modified to account for spatially autocorrelated observations by excluding not only the held-out observation, but also all observations within a distance threshold. It is clear from this article that no single validation method provides a comprehensive understanding of algorithm error, which highlights the importance of supervised learning using imperfect spatio-temporal data as a difficult data exploration problem. It is therefore also suggested that several complementary methods are regularly used to estimate the predictive accuracy of supervised learning algorithms, and statistical accuracy assessments that consider representativeness, dependence and smoothness issues are critically discussed.\n\n\n\n\nOverview of research design. CV: cross-validation; SLOOCV: Spatial leave-one-out cross-validation"
  },
  {
    "objectID": "Chapter7.html#reflection",
    "href": "Chapter7.html#reflection",
    "title": "7  Chapter 7 - Classification II",
    "section": "7.3 Reflection",
    "text": "7.3 Reflection\nThese weeks have been progressively more difficult and informative. Thanks to Andy’s explanations, I was able to gain more clarity on the week’s content. This week I learnt about classification and accuracy validation I learnt that we can’t balance two types of accuracy, user precision and producer accuracy, and that we need to be aware of the need to consider autocorrelation when doing cross-validation. Aside from this, I was initially confused by the Kappa coefficient, but after gaining a better understanding I learnt that the Kappa coefficient ranges from -1 to 1 and is used to assess the level of agreement between two sets of data, allowing researchers to assess the accuracy of classification algorithms and identify areas where improvements can be made to improve the accuracy of classification algorithms."
  },
  {
    "objectID": "index.html#about-yuanru-gao",
    "href": "index.html#about-yuanru-gao",
    "title": "Remote Sensing Cities and Environments Book",
    "section": "About Yuanru Gao",
    "text": "About Yuanru Gao\n My name is Yuanru Gao. I obtained a bachelor’s degree in Geographic Information Science in China in 2022. My areas of interest are WebGIS and indoor navigation. During my undergraduate studies, I was awarded a professional patented software copyright for Jinan Wisdom Spring System for Tourism V1.0. I am now studying Urban Spatial Science at University College London to pursue my dream as a spatial science researcher. As you see above, I am also a dancer and actress. In my spare time, I would like to go to take a dance video as long as I have new inspiration.^_^"
  },
  {
    "objectID": "Chapter4.html#city-introduction",
    "href": "Chapter4.html#city-introduction",
    "title": "4  Chapter 4 - Policy",
    "section": "4.1 City introduction",
    "text": "4.1 City introduction\n\nShanghai Shanghai, is one of the four direct-administered municipalities of the People’s Republic of China (PRC). The city is located on the southern estuary of the Yangtze River, with the Huangpu River flowing through it. The population of the city proper is the third most populous in the world, with 24.89 million inhabitants in 2021, while the urban area is the most populous in China with 39,300,000 residents. As of 2018, the Greater Shanghai metropolitan area was estimated to produce a gross metropolitan product (nominal) of nearly 9.1 trillion RMB ($1.33 trillion). Shanghai is one of the world’s major centers for finance, business and economics, research, science and technology, manufacturing, transportation, tourism, and culture, and the Port of Shanghai is the world’s busiest container port. Source: wikipedia\n\n\n\n\nShanghai"
  },
  {
    "objectID": "Chapter4.html#summary-of-the-policy",
    "href": "Chapter4.html#summary-of-the-policy",
    "title": "4  Chapter 4 - Policy",
    "section": "4.2 summary of the policy",
    "text": "4.2 summary of the policy\n\n4.2.1 Globao policy\n\nC40 is a network of mayors of nearly 100 world-leading cities collaborating to deliver the urgent action needed right now to confront the climate crisis. Together, we can create a future where everyone, everywhere can thrive.\n\n\n1.5°C Climate Action Plans C40’s Climate Action Planning programme supports cities around the world to create and implement climate action plans in line with the 1.5°C target of the Paris Agreement.\nHigh-Impact Accelerators C40 Accelerators demonstrate the highest-level of mayoral leadership on urgent climate action. They are based on the most ambitious, science-based targets and lay out concrete delivery milestones, both for mitigation and adaptation.\nInclusive & Thriving Cities n the midst of climate breakdown, mayors are facing multiple interlinked crises, including the COVID-19 pandemic and persisting social injustices. A Global Green New Deal with inclusive climate action at its heart is needed to build thriving communities that work for everyone.\n\n\n\n4.2.2 Local policy\n\nConnecting Delta Cities Network By 2050, the majority of the world’s population will live in cities in or near deltas, estuaries or coastal zones. This trend will increase the risk of extreme climate change related events, and the vulnerability of delta cities is expected to increase in the decades to come.The Connecting Delta Cities Network, led by the City of Rotterdam, brings together delta cities to address sea-level rise, discuss coastal flooding and water management issues and exchange knowledge and best practice to support cities in implementing solutions.\nPrivate Building Efficiency Network Energy consumed in buildings accounts for almost half of C40 cities’ carbon emissions on average, and around two-thirds of this comes from private buildings. Buildings can last over 100 years, which means that increasing a building’s energy efficiency is critical to meeting global climate goals. Improving building energy efficiency can bring many other additional benefits such as reduced energy bills, healthier workplaces, new jobs and greater energy security.Cities participating in the network have prioritized four focus areas around which they are actively sharing policies, strategies, ideas and challenges with one another.\nContinuously promoting the response to climate change and promoting synergy in reducing pollution and carbon emissions Deepening the construction of the local carbon market and strengthening the management of third-party verification agencies, Shanghai’s carbon-emitting enterprises completed 100% compliance for the eighth consecutive year. Actively promoting the creation of low-carbon demonstrations during the 14th Five-Year Plan period, issuing the “Shanghai Low Carbon Demonstration Creation Work Plan”, and innovating the construction of near-zero carbon emission practice zones and communities. We explored the fine-grained management of greenhouse gases and launched pilot district-level greenhouse gas inventories in Changning District and Jinshan District.\n\nSource:Shanghai EcologicalandEnvironmental Bulletin"
  },
  {
    "objectID": "Chapter4.html#rs-contribution",
    "href": "Chapter4.html#rs-contribution",
    "title": "4  Chapter 4 - Policy",
    "section": "4.3 RS contribution",
    "text": "4.3 RS contribution\n\n4.3.1 RS data\n\nLandsat 5 Since 1984, Landsat 5 has gathered more than 700,000 images and observed climate change, agricultural practices, development and urbanization of cities, ecosystem evolution, and increasing demand for natural resources.The Landsat Thematic Mapper (TM) sensor was carried on Landsat 4 and Landsat 5, and created images consisting of six spectral bands with a spatial resolution of 30 meters for Bands 1-5 and 7, and one thermal band (Band 6).\nLandsat8 The remote sensing equipment installed on LCDM includes a multichannel scanning radiometer OLI (Operational Land Imager) and a two-channel – IR radiometer TIRS (Thermal Infrared Sensor). The OLI instrument, developed by Ball Aerospace & Technologies, operates at nine wavelengths in the range of 0.433-2.300 μm and provides images with a maximum resolution of 15 m using advanced space imagery technologies. For their development, the experimental EO-1 satellite (launched in 2000 and equipped with the Advanced Land Imager radiometer, a prototype of the OLI radiometer) was used. The spatial landsat 8 resolution of the images obtained with the TIRS instrument is 100 m. Its main purpose is to obtain surface temperature characteristics, and to study the process of heat and moisture transfer in the interests of the agricultural sector, water management, etc.\nSynthetic Aperture Radar Synthetic aperture radar is a way of creating an image using radio waves. The radio waves used in SAR typically range from approximately 3 cm up to a few meters in wavelength, which is much longer than the wavelength of visible light, used in making optical images. These wavelengths fall within the microwave part of the spectrum in the figure below.\n\n\n\n\nComparison of wavelength, frequency, and energy for the electromagnetic spectrum.\n\n\n\nSource: NASA’s Imagine the Universe"
  },
  {
    "objectID": "Chapter3.html#summary",
    "href": "Chapter3.html#summary",
    "title": "3  Chapter 3 - Remote sensing data and Corrections",
    "section": "3.1 Summary",
    "text": "3.1 Summary\n\n3.1.1 Corrections\n\n3.1.1.1 Geometric correction\n\n\n\n\n\n\nNote\n\n\n\n\n\nImage distortions due to\n\n\nImage distortion due to sensor imaging method\nEffect of changes in orientation elements outside the sensor\nImage point displacement due to terrain undulation\nImage distortion due to earth curvature\nImage distortion due to atmospheric refraction\nEffects of the Earth’s rotation Source:Principles and application of remote sensing by Jiabing Sun\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nSolution\n\n\nIdentify Ground Control Points (GPS) to match known points in the image and a reference dataset (1)local map (2)another image (3)GPS data from handheld device\nWe take the coordinates and model them to give geometric transformation coefficients\nlinear regression with our distorted x or y as the dependent or independent\nplot these and try to minimise the RMSE (Jensen sets a RMSE value of 0.5)\nThere are many transformation algorithms available to model the actual coordinates\n\n\n\n then..\n\n\n\n\n\n\n\n\nThis means for every value in the output (gold standard) pixel we can get a value in the original input image. The images are distorted as so might not completely overlap\n\n\nRMSE\n\n(1)(observed - predicted (the residual))^2\n(2)sum them and divide by number of data points\n(3)square root that total\n\n\nResample\n\n\n\n\nSource:Abdul Basith\n\n\n3.1.1.2 Atmospheric correction\n\nRelative(to something) Normalize intensities of different bands within a single image; Normalise intensities of bands from many dates to one date\nAbsolute(definitive) (1)Change digital brightness values into scaled surface reflectance, then compare thesescaled surface reflectance values across the planet (2)atmospheric radiative transfer models (3)However, nearly all assume atmospheric measurements are available which are used to “invert” the image radiance to scaled surface reflectance (4)The scattering and absorption information comes from atmopshierc radiative transfer code such as MODTRAN 4+ and the Second Simulation of the Satellite Signal in the Solar Spectrum (6S)\n\n\n\n\nFlowchart for various relative and absolute methods for atmospheric correction of satellite measured radiance.\n\n\n\nSource:researchgate\n\n\n\n3.1.1.3 Orthorectification / Topographic correction\nWhat is orthorectified imagery - Using elevation to enable accurate image georeferencing Imagery has an amazing amount of information, but raw aerial or satellite imagery cannot be used in a GIS until it has been processed such that all pixels are in an accurate (x,y) position on the ground.The orthorectification process requires: An accurate description of the sensor, typically called the sensor model; detailed information about the sensor location and orientation for every image; and an accurate terrain model, such as the World Elevation service available from ArcGIS Online. After imagery has been orthorectified, it can be used within a GIS and accurately overlaid with other data layers.\n\n\n\n\nA view captured from an oblique angle\n\n\n\n\n\n3.1.1.4 Radiometric\n\nRadiometric calibration, also known as radiometric correction, is important to successfully convert raw digital image data from satellite or aerial sensors to a common physical scale based on known reflectance measurements taken from objects on the ground’s surface. This type of correction is important for reliable quantitative measurements of the imagery.\n\n\n\n\nThe process of radiometric correction\n\n\n\nSource:"
  },
  {
    "objectID": "Chapter3.html#application",
    "href": "Chapter3.html#application",
    "title": "3  Chapter 3 - Remote sensing data and Corrections",
    "section": "3.2 Application",
    "text": "3.2 Application\n\nAtmospheric Correction of Multispectral VNIR Remote Sensing Data: Algorithm and Inter-sensor Comparison of Aerosol and Surface Reflectance Products(Mishra et al., 2020)\n\nThis paper presents an algorithm for aerosol optical depth (AOD) retrieval and AC of VNIR imaging data. Cartosat-2S MX datasets acquired in different regions of the world were used, covering parts of the Indian subcontinent (India, Nepal, Pakistan and Bangladesh), China and the USA. A total of 106 Cartosat-2S datasets obtained in January, July, November and December of 2016 and 2017 were used. Each Cartosat-2S dataset contains radiometric calibration radiation for all four bands. AOD, surface reflectance and NDVI obtained by processing Cartosat-106S MX data at 2 globally distributed locations were compared with the corresponding MODIS-terra products juxtaposed in time and space to test the performance of their algorithm.Cartosat-2S and MODIS-terra derived AOD, surface reflectance and NDVI The comparison shows very good correlation. the relative difference between Cartosat-2S AOD and MODIS-terra AOD is within 25%. It is concluded that the algorithm effectively eliminates atmospheric effects (aerosol-induced haze) and thus increases the contrast of the surface features.\n\nThermal infrared radiometric calibration of the entire Landsat 4, 5, and 7 archive (1982–2010)(Schott et al., 2012)\n\nThis paper describes the methods and procedures used to perform radiometric calibration of the earliest bulk thermal dataset in the archive (Landsat 4 data). In order to make proper use of the thermal data, we need to be able to convert the data to surface temperatures. A key step in this process is the complete and consistent calibration of the entire archive to absolute radiation so that it can be compensated in the atmosphere to the radiation left at the surface and then to the surface radiation temperature. The completion of this work and the updated calibration of the earlier (1985-1999) Landsat 5 data (also reported here) concludes a comprehensive calibration of the Landsat thermal data archive from 1982 to the present. Finally, while the results reported in this paper indicate that the Landsat archive is well calibrated with very small residual uncertainties, they also indicate the existence of small sources of uncertainty not accounted for by the error model. If these sources can be identified and are systematic rather than random, they may further reduce the errors (below 0.5 K). So it is still possible to continue to improve the error model."
  },
  {
    "objectID": "Chapter3.html#reflection",
    "href": "Chapter3.html#reflection",
    "title": "3  Chapter 3 - Remote sensing data and Corrections",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nIt was a very informative week in the classroom. The first part was calibration and I learnt that the points of the output diagram can be found from the original diagram after calibration, but not necessarily vice versa. There was also the need to resample after geometric corrections. Atmospheric corrections are divided into absolute and relative, and relative corrections require the selection of the base map and the constant elements. Another thing I learnt in class about atmospheric correction is that Atmospheric correction happens before topographic correction. Through this week I have gained a clearer understanding of the four correction methods and I have also gained an understanding of the second part of data joining and image enhancement, data joining can then be linked to the GIS course."
  },
  {
    "objectID": "Chapter5.html#summary",
    "href": "Chapter5.html#summary",
    "title": "5  Chapter 5 - Google Earth Engine",
    "section": "5.1 Summary",
    "text": "5.1 Summary\n\n5.1.1 What is Google Earth Engine\n\nGeospatial processing service\nIt permits geospatial analysis at scale\nProcess massive datasets\nStore data on servers\nTakes the code we have written and applies it for us\n\n\n\n5.1.2 Difference in data name\nImage-> raster(has bands); Feature-> Vector(has geometry and attributes) Stack-> Collection\n\n\n\n\nClient vs Server\n\n\n\nSource:pintrest/codeboxx\n\n\n5.1.3 Pratical\n\n5.1.3.1 Basic\n\nLoad data\n\n\nvar dataset = ee.ImageCollection('LANDSAT/LC09/C02/T1_L2')\n    .filterDate('2022-01-01', '2022-02-01');\n\n\nAdd it to our map, then the final Landsat 9 here is what the layer will be called on the map.\n\n\nMap.addLayer(dataset, {bands: [\"SR_B4\", \"SR_B3\", \"SR_B2\"]}, \"Landsat 9\")\n\n\nSingle images select a single image from the collection by filtering using the specific date, which you can get from the console window when printing the images within the collection. Landsat (and most other EO datasets) have the date within the file path name.\n\n\nvar oneimage = ee.ImageCollection('LANDSAT/LC09/C02/T1_L2')\n  .filterDate('2022-04-03', '2022-04-04')\n  .filterBounds(india);  // Intersecting ROI\n\n\n\n\n\nSingle image result\n\n\n\n\nMake a function and then calling our collection to the function\n\n\n// Applies scaling factors in a function\nfunction applyScaleFactors(image) {\n  var opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2);\n  var thermalBands = image.select('ST_B.*').multiply(0.00341802).add(149.0);\n  return image.addBands(opticalBands, null, true)\n              .addBands(thermalBands, null, true);\n}\n// call our collection to the function and assign it to a new variable \noneimage_study_area_cloud_scale = oneimage_study_area_cloud.map(applyScaleFactors);\n// apply the median reducer\nvar oneimage_study_area_cloud_scale_median = oneimage_study_area_cloud_scale.reduce(ee.Reducer.median());\n\nThen we map this result\n\n// set up some of the visualisation paramters \nvar vis_params = {\n  bands: ['SR_B4_median', 'SR_B3_median', 'SR_B2_median'],\n  min: 0.0,\n  max: 0.3,\n};\n// add a layer to the map\nMap.addLayer(oneimage_study_area_cloud_scale_median, vis_params, 'True Color (432)');\n\n\nClip Clip those images to our current study area, we also used the interactive visulisation box to select my min and max values.\n\n\nvar clip = meanImage.clip(india)\n  .select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']);\nvar vis_params3 = {\n  bands: ['SR_B4', 'SR_B3', 'SR_B2'],\n  min: 0,\n  max: 0.3,\n};\n// map the layer\nMap.addLayer(clip, vis_params3, 'clip');\n\n\n\n\n\n\n\nTrue Color image result\n\n\n\n\n\n\n\nClip image result\n\n\n\n\n\n\n\n5.1.3.2 PCA\nFirst method I use (part of codes):\nSource: ZhiHu\n\n//- PCA\n// Principal Components Analysis EXAMPLE\n\n// Load a landsat 8 image, select the bands of interest.\nvar image = ee.Image('LANDSAT/LC08/C02/T1_L2/LC08_146040_20211127')\n  .select([ 'SR_B3', 'SR_B4', 'SR_B5']);\n\n// Display the input imagery and the region in which to do the PCA.\nvar region = image.geometry();\nMap.centerObject(region, 10);\nMap.addLayer(ee.Image().paint(region, 0, 2), {}, 'Region');\nMap.addLayer(image, {bands: ['SR_B3', 'SR_B4', 'SR_B5'], min: 0, max: 20000}, 'Original Image');\n\n// Get some information about the input to be used later.\nvar scale = image.projection().nominalScale();\nvar bandNames = image.bandNames();\n\n// Mean center the data to enable a faster covariance reducer \n// and an SD stretch of the principal components.\nvar meanDict = image.reduceRegion({\n    reducer: ee.Reducer.mean(),\n    geometry: region, \n    scale: scale,\n    maxPixels: 1e9\n});\nvar means = ee.Image.constant(meanDict.values(bandNames));\nvar centered = image.subtract(means);\n\n// This helper function returns a list of new band names.\nvar getNewBandNames = function(prefix) {\n  var seq = ee.List.sequence(1, bandNames.length());\n  return seq.map(function(b) {\n    return ee.String(prefix).cat(ee.Number(b).int());\n  });\n};\n\n// This function accepts mean centered imagery, a scale and \n// a region in which to perform the analysis.  It returns the \n// Principal Components (PC) in the region as a new image.\n// [START principal_components]\nvar getPrincipalComponents = function(centered, scale, region) {\n  // Collapse the bands of the image into a 1D array per pixel.\n  var arrays = centered.toArray();\n});\n\nSecond method I use:(part of codes)\nSource: Andy MacLachlan\n\nvar bounds = india.geometry().bounds();\n\n//var clip2 = ee.Image(meanImage_texture)\n\n// scale and band names\nvar scale = 30;\nvar bandNames = glcm.bandNames();\n\nvar region = india.geometry();\nMap.centerObject(region, 10);\nMap.addLayer(ee.Image().paint(region, 0, 2), {}, 'Region');\n\nprint(region, \"india_geometry\")\n\n// mean center the data and SD strech the princapal components \n// and an SD stretch of the principal components.\nvar meanDict = glcm.reduceRegion({\n    reducer: ee.Reducer.mean(),\n    geometry: region,\n    scale: scale,\n    maxPixels: 1e9\n});\nvar means = ee.Image.constant(meanDict.values(bandNames));\nvar centered = glcm.subtract(means);\n\n// This helper function returns a list of new band names.\nvar getNewBandNames = function(prefix) {\n  var seq = ee.List.sequence(1, bandNames.length());\n  return seq.map(function(b) {\n    return ee.String(prefix).cat(ee.Number(b).int());\n  });\n};\n\n// This function accepts mean centered imagery, a scale and\n// a region in which to perform the analysis.  It returns the\n// Principal Components (PC) in the region as a new image.\nvar getPrincipalComponents = function(centered, scale, region) {\n  // Collapse the bands of the image into a 1D array per pixel.\n  var arrays = centered.toArray();\n\n  // Compute the covariance of the bands within the region.\n  var covar = arrays.reduceRegion({\n    reducer: ee.Reducer.centeredCovariance(),\n    geometry: region,\n    scale: scale,\n    maxPixels: 1e9\n  });\n\n  // Get the 'array' covariance result and cast to an array.\n  // This represents the band-to-band covariance within the region.\n  var covarArray = ee.Array(covar.get('array'));\n\n  // Perform an eigen analysis and slice apart the values and vectors.\n  var eigens = covarArray.eigen();\n\n});\n\n\n\n5.1.3.3 Difference in these two methods\nThe first code, the Landsat 8 imagery is preprocessed to create a composite of the median pixel values for each band, which is then used to compute the PCA. In the second code, the GLCM texture matrix is computed directly from the Landsat 8 imagery, and then mean-centered and standardized before PCA is computed."
  },
  {
    "objectID": "Chapter5.html#application",
    "href": "Chapter5.html#application",
    "title": "5  Chapter 5 - Google Earth Engine",
    "section": "5.2 Application",
    "text": "5.2 Application\n\nImpacts of droughts and floods on croplands and crop production in Southeast Asia – An application of Google Earth Engine(Venkatappa et al., 2021)\n\nIn this study, PDSI data were examined using the GEE during the main crop-growing seasons, May to November for the MCR and October to April for the ECR over the 40 years from 1980 to 2019. The temporal drought conditions in the MCR and ECR were assessed during the crop-growing seasons between 1980 and 2019. Here, dryness refers to droughts conditions and wetness refers to floods as defined by the values of PDSI. JavaScript programming language was used in the GEE to collect the PDSI monthly time series data during the crop-growing seasons in the SEA region. The earth engine filter date function was applied to reduce the PDSI dataset from 1980 to 2019 and generate the PDSI temporal profiles for each MCR and ECR country using international boundaries in the GEE. The generated PDSI profiles by country were computed in the GEE and then, exported outside the GEE for generating seasonal PDSI profiles using Microsoft Excel. Further, the PDSI values were extracted into grid points using the value extraction function by country from 2015 to 2019 in the GEE. When using GEE it is inevitable that we will encounter problems due to network connectivity and network timeouts, but the benefits are online operation, the ability to save to the cloud and the ease of loading data from the library.\n\n\n\n\nExample of 47,192 grid points imported into Google Earth Engine for determining the PDSI values for categorising the drought and floods levels and events"
  },
  {
    "objectID": "Chapter5.html#reflection",
    "href": "Chapter5.html#reflection",
    "title": "5  Chapter 5 - Google Earth Engine",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\nThis week I have been practising mostly Practical, from simply creating points to implementing Principal Component Analysis. I learnt how to create a GEE project, which is very simple to use, mainly in Javascript, and is extremely convenient because it allows you to search for remote sensing data and geographic data online as well as import local data. When creating points we can point directly from the map and the code is automatically generated, or we can define our own point attributes and coordinates. When practising the code given by the teacher, I encountered two errors, but I managed to solve them after searching for information and consulting with Andy. One of the problems was the definition of a method for principal component analysis, which worked successfully after Andy’s answer. I also tried to find other alternatives before solving the problem, tried to define the bands myself and also ran the code successfully. What I have learnt so far is not enough and I will continue to use GEE to complete more remote sensing data analysis in the future."
  },
  {
    "objectID": "Chapter8.html#summary",
    "href": "Chapter8.html#summary",
    "title": "8  Chapter 8 - Temperature",
    "section": "8.1 Summary",
    "text": "8.1 Summary\n\n8.1.1 Urban Heat Island\n\nWhat is UHI?\n\n\nurban areas obtain comparatively higher atmospheric and surface temperatures than surrounding rural areas\n\n\nFactors cause UHI\n\n(1)Main factors - More dark surfaces that retain heat - Less vegetation that cools the environment (evapotranspiration and solar blocking)\n(2)Other factors - A low Sky View Factor (SVF) - Air speed, cloud cover, cyclic solar radiation, building material type and anthropogenic energy\n\n\n\n\nFactors responsible for Urban Heat Island Effect. (Source – Osmond, 2017)\n\n\n\n\n\n8.1.2 Policy\n\n8.1.2.1 Global\n\nNew Urban Agenda = standards and principles for planning, construction, development, management and urban improvement(Point 37,54,79)\nSustainable Development Goals (SDG) = targets with measurable indicators for monitoring(Goal 11)\nBeat The Heat Handbook(Chapter 5)\n\n\n\n8.1.2.2 Local\n\nSuperblocks\nMedellín Green Corridors\nSydney’s western suburbs\n\n\n\n8.1.2.3 What prooblem these policy have?\n\nThey don’t actually give specifics, like what sort of planning rules need to be changed.\nIf you are a planner how should you consider applications given this guidance / requirements\nIs it up to metropolitan level / national level and not individual planning applications\n\n\n\n\n8.1.3 Data\nWhat datasest tell us? It is related to temperature?\n\n\n\n\nAmericans who live with hotter temperatures\n\n\n\n\n\n8.1.4 Vegetation area selection\n\nFremantle’s Urban Forest Plan Fremantle selected the areas based on topography and geology- two aspects that influence tree species from and density. But they did not consider the size of trees.\n\nSource :City of Fremantle\n\n\n\n\nCity of Fremantle\n\n\n\n\n\n8.1.5 Reconsideration\nBased on local conditions, MacLachlan and his team focus on Mean radiant temperature (MRT).\n\nSource :MacLachlan et al. 2021\n\n\n\n8.1.6 Approaching projects\n\nSearch for EO data\nIdentify an issue (look at local policy documents)\nLook at global policy documents \nWhat can be solved with the data?\nWhat could this data contribute to another question? (e.g. including it as a variable)\nHow could the remotely sensed data be included within a data workflow \nConsider Anything else as long as it includes EO data …"
  },
  {
    "objectID": "Chapter8.html#application",
    "href": "Chapter8.html#application",
    "title": "8  Chapter 8 - Temperature",
    "section": "8.2 Application",
    "text": "8.2 Application\n\nFine-scale modeling of the urban heat island: A comparison of multiple linear regression and random forest approaches(Oukawa et al., 2022)\n\nThis paper develops specific daytime and night-time multiple linear regression (MLR) and random forest (RF) models to analyse and predict the spatial and temporal evolution of urban heat island intensity (UHII), using air temperature (Tair) as a response variant. The study area was chosen to be Londrina, a city in southern Brazil. The study is rich in data, with in situ Tair data and a comprehensive pool of predictive variables - including land cover, population, traffic, urban geometry, weather data and atmospheric vertical indexes. The steps of the first model MLR are (1) the highest-ranking variable (most correlated with the response variable) of each sub-category was identified; (2) variables within each sub-category that were correlated (Pearson’s |R| > 0.60) with the highest-ranking variable were removed; (3) the remaining variables were verified and removed if they did not match the variance inflation factor (VIF) < 3. The second random forest model, constructed by averaging predictors learned from regression or classification trees. Each tree is built from multiple bootstrapped datasets and, at each split, a random sample of m predictors are selected as candidates from the full array. Unlike bagging, this method de-correlates individual trees, reducing variance in the dataset, since they are not all dependent on the same data or same variables. It was concluded that the MLR model explained a lower percentage of the variance, which could be attributed to the complex non-linear interactions of the selected predictor variables with Tair. On the other hand, the RF model outperformed the MLR model and was able to explain a larger percentage of the variance during the day and night and under different weather conditions. In addition, the RF model is able to capture and map the fine-scale spatial and temporal variability of UHII across the study area. Such machine learning techniques could provide urban planners with a reliable framework for predicting and mitigating the impacts of the UHI. While this may be challenging in developed cities, the problem of improving the microclimate of new communities can be avoided by avoiding the use of large areas of impervious material.\n\n\n\n\nSpatiotemporal evolution of the modeled UHII for selected days under different weather conditions (clusters) and selected times of day (a–l)\n\n\n\n\nRemote sensing based analysis of urban heat islands with vegetation cover in Colombo city, Sri Lanka using Landsat-7 ETM+ data((Senanayake et al., 2013))\n\nIn this study, the thermal band (10.40-12.50 lm) of Landsat-7 ETM+ images acquired on 3 different dates covering the city of Colombo, Sri Lanka, was analysed for spatial and temporal identification of the UHI. The vegetation cover of Colombo City was extracted using the NDVI method and subsequently examined using the distribution of LST. Based on the distribution of LST and the availability of vegetation cover, a deductive index was defined to identify environmentally critical areas in Colombo City. The following conclusions were reached in this paper, firstly based on surface temperature and vegetation cover, Colombo Harbour and the surrounding areas in the north-western part of the city of Colombo were identified as the most environmentally critical areas. Areas with extensive asphalt paving were then identified as the main source of elevated surface temperatures. In addition, the Colombo-Galle A2 road appears to be an environmentally critical area based on vegetation cover and surface temperature availability. The advantage of this project is that the methodology is basic and widely applicable and can be applied to other cities to determine the formation of the UHI."
  },
  {
    "objectID": "Chapter8.html#reflection",
    "href": "Chapter8.html#reflection",
    "title": "8  Chapter 8 - Temperature",
    "section": "8.3 Reflection",
    "text": "8.3 Reflection\nThis week’s learning has been very helpful to me as the topic of the group work assignment is also addressing the Urban Heat Island effect. I have learnt this week to think about the kind of questions that need to be considered when developing a project and have practiced exploring how data can explain a research question. I learnt about all the satellite data that can be used to extract surface temperatures and the pros and cons between them. For example, thermal infrared sensor data can measure reflected and emitted radiation from the surface. This radiation contains information about the surface temperature, which can be deduced by calculating the intensity of the radiation. In addition to this I learnt how to extract temperature results. Also, thanks to Andy for the project examples, which broadened my thinking about the heat island effect."
  },
  {
    "objectID": "Chapter6.html#reference",
    "href": "Chapter6.html#reference",
    "title": "6  Chapter 6 - Classification I",
    "section": "6.4 Reference",
    "text": "6.4 Reference\nDong, L., Du, H., Mao, F., Han, N., Li, X., Zhou, G., Zhu, D., Zheng, J., Zhang, M., Xing, L., Liu, T., 2020. Very High Resolution Remote Sensing Imagery Classification Using a Fusion of Random Forest and Deep Learning Technique—Subtropical Area for Example. IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens. 13, 113–128. https://doi.org/10.1109/JSTARS.2019.2953234  Pal, M., 2005. Random forest classifier for remote sensing classification. Int. J. Remote Sens. 26, 217–222. https://doi.org/10.1080/01431160412331269698"
  },
  {
    "objectID": "Chapter7.html#reference",
    "href": "Chapter7.html#reference",
    "title": "7  Chapter 7 - Classification II",
    "section": "7.4 Reference",
    "text": "7.4 Reference\nStock, A., 2022. Spatiotemporal distribution of labeled data can bias the validation and selection of supervised learning algorithms: A marine remote sensing example. ISPRS J. Photogramm. Remote Sens. 187, 46–60. https://doi.org/10.1016/j.isprsjprs.2022.02.023"
  },
  {
    "objectID": "Chapter4.html#application---how-it-works",
    "href": "Chapter4.html#application---how-it-works",
    "title": "4  Chapter 4 - Policy",
    "section": "4.4 Application - How it works",
    "text": "4.4 Application - How it works\nThe impact of carbon emissions on the environment is particularly prominent in the global climate crisis. Shanghai has also launched a series of policies and projects to address this phenomenon. Remote sensing technology can be used to monitor carbon emissions, for example by indirectly using temperature to reflect changes in carbon emissions.\n\nLandsat 5 TM and Landsat 7 ETM+ have six reflective bands (visible, near-infrared, and short-wavelength infrared, 30-m spatial resolution) and one band in the TIR region (Band 6). The thermal band has a native spatial resolution of 120-m and 60-m for TM and ETM+, respectively, but it is delivered by USGS at 30-m after cubic convolution resampling. The Landsat 8 OLI sensor has nine reflective bands with 30-m spatial resolution, and Landsat 8 TIRS sensor has two bands in the TIR region (Band 10 and Band 11). These thermal bands have a 100-m native spatial resolution but resampled and published at 30 m by USGS.(Sekertekin and Bonafoni, 2020)\n\n\n\n\n\nLandsat 8 LST image\n\n\n\n\nIn addition to surface temperature results to reflect carbon emissions, projects in Shanghai have trie remotely sensing technology too get aboveground carbon storage.(Li, 2023) They used single Landsat 8 (L) remote sensing data, single Sentinel-2 (S) remote sensing data and combined Landsat 8 and Sentinel-2 (L+S) data as data sources. Four machine learning methods, Support Vector Regression (SVR), Random Forest (RF), XGBoost (extreme gradient boosting) and CatBoost (classification boosting), were used to predict the forest AGC based on the two forest sample sites in Shanghai.\n\n\n\n\n\nAccuracy evaluation of AGC prediction based on Landsat 8 and Sentinel-2 (L + S) using four machine learning models."
  },
  {
    "objectID": "Chapter4.html#reflection",
    "href": "Chapter4.html#reflection",
    "title": "4  Chapter 4 - Policy",
    "section": "4.5 Reflection",
    "text": "4.5 Reflection\nIn the fourth week, I read a lot of literature and policy documents where environmental issues were more appealing to me. So I paid particular attention to the C40 programme, which is a very well-established worldwide policy where each city enters into agreements and makes improvements according to its own situation. Some are still ongoing programmes, and others have already had some success. After listening to the class I realised that I still need to think about what kind of data can be effective for implementing programmes, as many local policies and plans are launched without a very complete and concrete approach to their realisation, and cities develop policies that tend to focus on legislation or monitoring rather than prevention. These are all things I need to be aware of when setting up the project and moving forward with it."
  },
  {
    "objectID": "Chapter8.html#reference",
    "href": "Chapter8.html#reference",
    "title": "8  Chapter 8 - Temperature",
    "section": "8.4 Reference",
    "text": "8.4 Reference\nOukawa, G.Y., Krecl, P., Targino, A.C., 2022. Fine-scale modeling of the urban heat island: A comparison of multiple linear regression and random forest approaches. Sci. Total Environ. 815, 152836. https://doi.org/10.1016/j.scitotenv.2021.152836 Senanayake, I.P., Welivitiya, W.D.D.P., Nadeeka, P.M., 2013. Remote sensing based analysis of urban heat islands with vegetation cover in Colombo city, Sri Lanka using Landsat-7 ETM+ data. Urban Clim. 5, 19–35. https://doi.org/10.1016/j.uclim.2013.07.004"
  },
  {
    "objectID": "Chapter5.html#reference",
    "href": "Chapter5.html#reference",
    "title": "5  Chapter 5 - Google Earth Engine",
    "section": "5.4 Reference",
    "text": "5.4 Reference\nVenkatappa, M., Sasaki, N., Han, P., Abe, I., 2021. Impacts of droughts and floods on croplands and crop production in Southeast Asia – An application of Google Earth Engine. Sci. Total Environ. 795, 148829. https://doi.org/10.1016/j.scitotenv.2021.148829"
  },
  {
    "objectID": "Chapter4.html#reference",
    "href": "Chapter4.html#reference",
    "title": "4  Chapter 4 - Policy",
    "section": "4.6 Reference",
    "text": "4.6 Reference\nLi, H., Zhang, G., Zhong, Q., Xing, L., Du, H., 2023. Prediction of Urban Forest Aboveground Carbon Using Machine Learning Based on Landsat 8 and Sentinel-2: A Case Study of Shanghai, China. Remote Sens. 15, 284. https://doi.org/10.3390/rs15010284 Sekertekin, A., Bonafoni, S., 2020. Land Surface Temperature Retrieval from Landsat 5, 7, and 8 over Rural Areas: Assessment of Different Retrieval Algorithms and Emissivity Models and Toolbox Implementation. Remote Sens. 12, 294. https://doi.org/10.3390/rs12020294"
  },
  {
    "objectID": "Chapter3.html#reference",
    "href": "Chapter3.html#reference",
    "title": "3  Chapter 3 - Remote sensing data and Corrections",
    "section": "3.4 Reference",
    "text": "3.4 Reference\nMishra, M.K., Rathore, P.S., Misra, A., Kumar, R., 2020. Atmospheric Correction of Multispectral VNIR Remote Sensing Data: Algorithm and Inter‐sensor Comparison of Aerosol and Surface Reflectance Products. Earth Space Sci. 7. https://doi.org/10.1029/2019EA000710 Schott, J.R., Hook, S.J., Barsi, J.A., Markham, B.L., Miller, J., Padula, F.P., Raqueno, N.G., 2012. Thermal infrared radiometric calibration of the entire Landsat 4, 5, and 7 archive (1982–2010). Remote Sens. Environ. 122, 41–49. https://doi.org/10.1016/j.rse.2011.07.022"
  },
  {
    "objectID": "Chapter2.html#xaringan-presentation",
    "href": "Chapter2.html#xaringan-presentation",
    "title": "2  Xaringan and Quarto",
    "section": "2.1 Xaringan presentation",
    "text": "2.1 Xaringan presentation\nMy presentation about Sentinel is available here."
  },
  {
    "objectID": "Chapter2.html#source",
    "href": "Chapter2.html#source",
    "title": "2  Xaringan and Quarto",
    "section": "2.2 Source",
    "text": "2.2 Source\n\nXaringan operation instruction\nXaringan CSS theme generator"
  },
  {
    "objectID": "Chapter1.html#reference",
    "href": "Chapter1.html#reference",
    "title": "1  Chapter 1 - Introduction to Remote Sensing",
    "section": "1.4 Reference",
    "text": "1.4 Reference\nRamsey, M., Flynn, I., 2020. The Spatial and Spectral Resolution of ASTER Infrared Image Data: A Paradigm Shift in Volcanological Remote Sensing. Remote Sens. 12, 738. https://doi.org/10.3390/rs12040738 Verde, N., Mallinis, G., Tsakiri-Strati, M., Georgiadis, C., Patias, P., 2018. Assessment of Radiometric Resolution Impact on Remote Sensing Data Classification Accuracy. Remote Sens. 10, 1267. https://doi.org/10.3390/rs10081267"
  }
]